# - 海量日志数据，提取出某日访问百度次数最多的那个IP

题目的隐藏含义就是海量日志数据不能一次读取到内存中，否则直接用HashMap统计IP出现的频率（IP为key，频率为Value），然后按照频率排序就好了。

 这道题的做法是先对文件遍历一遍，将一天访问百度的IP记录到一个单独的文件，如果这个文件还是很大，可以对IP进行hash取余，将IP映射到多个文件中，然后利用HashMap统计每个文件中IP的频率，分别找到每个文件中频率最高的IP，再从这些IP中找到整体频率最高的IP。

 如果是频率最高的前N个怎么办？这时可以在利用HashMap统计每个文件中IP的频率后，维护一个小顶堆，找到TopN。具体方法是：依次遍历每个小文件，构建一个小顶堆，堆大小为 N。如果遍历到的IP的出现次数大于堆顶IP的出现次数，则用新IP替换堆顶的IP，然后重新调整为小顶堆，遍历结束后，小顶堆上的词就是出现频数最高的 N 个IP。

# - 寻找热门查询，300万个查询字符串中统计最热门的10个查询

题目详细描述：搜索引擎会通过日志文件把用户每次检索使用的所有查询串都记录下来，每个查询床的长度不超过 255 字节。假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门），请你统计最热门的10个查询串，要求使用的内存不能超过1G。 这也就是热榜的简单实现，当然实际的热榜会复杂很多，毕竟还要考虑一部分人要撤热搜或降热度等需求。

**方法一：分治+HashMap** 

还是前面的老方法，先用Hash映射将查询字符串映射到多个小文件中，然后用HashMap统计每个小文件中查询字符串出现的频率（key为热门字符串，value为频率），找到每个小文件中的频率最高的top10，最后通过一个小顶堆统计所有小文件中的top10。

**方法二：直接用HashMap** 

题目中写道，去重后只有300w条数据，每条查询不超过255字节，一共是700多M，小于1G。所以可以直接遍历查询字符串，并存入到HashMap中（key为热门字符串，value为频率），通过小顶堆找到频率最高的top10

 **方法三：前缀树** 

只是把方法二中的HashMap换成了前缀树，在遍历字符串时，在前缀树中查找该字符串，如果找到，则将节点中保存的当前前缀的次数加1，没有找到，则为这个字符串构建新结点，并将新构建的结点中的次数置为1。最后还是通过小顶堆找到频率最高的top10

# - 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词

方法还是前面的分治+HashMap+小顶堆 首先遍历文件，对每个词进行hash，比如hash(x)%5000，将所有词分别存入到5000个小的文件中，每个文件大概200k左右，然后通过HashMap统计每个小文件中词的频率（key为词，value为频率）。对于每个遍历到的词，如果在HashMap中，则将value值加1，不在HashMap中，则将词存入HashMap，并将值置为1。最后构建小顶堆，堆的大小为100，找到频率最高的100个词。



# -有一个英文百科全书，如何找出其中出现次数最多的单词？

分治+字典树统计



# 10亿数据找到前100大的数（Top K问题）

### **1. 思路**

取文件中前K个数在内存中维护一个长度为K的小顶堆，然后从文件中挨个读取数字并和堆顶比较，如果比堆顶小则直接丢弃，否则替换堆顶后调整[小顶堆](https://zhida.zhihu.com/search?content_id=186262407&content_type=Article&match_order=6&q=小顶堆&zhida_source=entity)。遍历完文件中所有的数字后，小顶堆中的K个数就是所求的Top K。

### **2. 优点**

只需要遍历一次文件中的数字，不存在多次读写数据的问题。

### **3. 复杂度**

- 时间复杂度：最好情况下文件中前K个数就是Top K，遍历一遍文件即可，[时间复杂度](https://zhida.zhihu.com/search?content_id=186262407&content_type=Article&match_order=7&q=时间复杂度&zhida_source=entity)为 𝑂(𝑛) ；最坏情况下遍历文件中每个数都需要调整小顶堆，时间复杂度为 𝑂(𝑛𝑙𝑜𝑔2𝑘)
- 空间复杂度：只需要在内存中维护小顶堆，[空间复杂度](https://zhida.zhihu.com/search?content_id=186262407&content_type=Article&match_order=6&q=空间复杂度&zhida_source=entity)为 𝑂(𝑘)

### **4. 优化**

可以通过[并行计算](https://zhida.zhihu.com/search?content_id=186262407&content_type=Article&match_order=1&q=并行计算&zhida_source=entity)（多线程或者分布式运算）的方式进一步提高算法效率：

- 通过Hash方法将n个数据随机切分成m份，需要的时间复杂度为 𝑂(𝑛)
- 对于m份[数据并行](https://zhida.zhihu.com/search?content_id=186262407&content_type=Article&match_order=1&q=数据并行&zhida_source=entity)使用小顶堆选出最大的k个数据，需要的时间复杂度为 𝑂(𝑛𝑚𝑙𝑜𝑔2𝑘) ，运算完后得到m组长度为k的**小顶堆**
- 并行对上步每一个小顶堆进行[堆排序](https://zhida.zhihu.com/search?content_id=186262407&content_type=Article&match_order=1&q=堆排序&zhida_source=entity)，得到m个长度为k的有序序列，时间复杂度为 𝑂(𝑘𝑙𝑜𝑔2𝑘)
- [二分查找](https://zhida.zhihu.com/search?content_id=186262407&content_type=Article&match_order=1&q=二分查找&zhida_source=entity)取出m个有序序列中最大的数，遍历k次即可，时间复杂度为 𝑂(𝑘𝑙𝑜𝑔2𝑚)

由于第二步和第三步可以并行计算，因此总的时间复杂度为：

𝑂(𝑛+(𝑛𝑚+𝑘)𝑙𝑜𝑔2𝑘+𝑘𝑙𝑜𝑔2𝑚)

对比没有并行的小顶堆算法，可以发现算法得到了常数级别的优化。

**实际情况**

实际处理大数据Top K问题时，需要考虑两个问题：

- 是否并发：并发可以显著提高运行速度，单机多核可以使用Hash将数据划分为多份子数据然后多线程并发排序，多机可以使用Hash+Socket方法将数据分发到多台机器上
- 是否有足够内存：如果机器内存足够可以直接在内存中使用Hash对数据进行切分，如果机器内存不足可以将[原始文件](https://zhida.zhihu.com/search?content_id=186262407&content_type=Article&match_order=1&q=原始文件&zhida_source=entity)切分成多个小文件

在实际开发中，如果机器有足够内存就直接在内存中处理即可，机器有多个核时也可以使用多线程并发处理。



